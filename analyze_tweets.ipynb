{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizando tuits\n",
    "\n",
    "[Pablo Haya](http://pablohaya.com), Ultima versión: Mar-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Este _notebook_ presenta analisis y visualizaciones básicas sobre el conjunto de tuits descargados en la práctica anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización\n",
    "\n",
    "Primeramente se cargan las bibliotecas necesarias para realizar el análisis de datos, `pandas`, y para la visualización `matplotlib`. Se añaden también bibliotecas auxiliares para procesar el formato JSON, y para poder utilizar expresiones regulares `re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bibliotecas necesarias\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los tuits descargados en la práctica anterior. En el caso de que se haya tenido alguna dificultad se puede utilizar el conjunto de datos de ejemplo que acompaña a este práctica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lee el dataset descargado anteriormente\n",
    "# Es preciso incluir el nombre del fichero correcto\n",
    "tweets_data_path = 'twitter_stream_data.json'\n",
    "\n",
    "tweets_data = []\n",
    "with open(tweets_data_path, \"r\") as tweets_file:\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos cuantos tweets hay\n",
    "print(len(tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada tuit se describe mediante el formato JSON como vamos a poder ver a continuación imprimiendo el primer tuit descargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(tweets_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede comprobar, cada tuit incluye un gran cantidad de metainformación adicional que se puede explotar a parte del texto. La descripción completa de los campos de un tuit se puede encontrar en: https://dev.twitter.com/overview/api/tweets.\n",
    "\n",
    "El siguiente ejemplo muestra la estructura de un tuit reflejando los campos más importantes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"created_at\": \"Tue Apr 03 06:34:43 +0000 2018\",\n",
    "  \"id\": 981057390220017700,\n",
    "  \"id_str\": \"981057390220017664\",\n",
    "  \"text\": \"Hadoop training done know what are the career opportunities to utilize https://t.co/uqUxnZIm76\",\n",
    "  \"favorite_count\":, \n",
    "  \"retweet_count\":,\n",
    "  \"user\": {...},\n",
    "  \"entities\": {...},\n",
    "  \"lang\": \"en\",\n",
    "  \"coordinates\": {...}, \n",
    "  \"place\": {...}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`id` e `id_str` identifican univocamente un tuit que ha sido creado en la fecha indicada por el atributo `created_at`. \n",
    "\n",
    "Los atributos `favorited_count` y `retweet_count`indican aproximadamente el número de favoritos y retuits que ha recibido el tuit hasta el momento. Es posible conseguir el valor actualizado de estos atributos preguntando de nuevo a la API especificando el identificador del tuit como parámetro de la función `get_status`.\n",
    "\n",
    "El atributo `user` incluye una estructura con información detallada sobre el usuario que ha emitido el tuit como el número de seguidores y seguidos, si es una cuenta verificada, o el número de tuits entre otros. En el campo `entities` podemos encontrar la lista de hashtags incluidos en el tuit o las URLS entre otros.\n",
    "\n",
    "Los tuits geolocalizados incluyen información de la posición en dos niveles. Dentro del objeto `coordinates` podemos encontrar la coordenadas exactas (longitud y latitud), mientras que el objeto `place` representa la localiación como un región ya sea mediante un etiqueta, como puede ser el pais o el nombre de la ciudad, o mediante un polígono. La información de localización es opcional, por lo que no está presente en todos los tuits. Puede ser que se disponga del  lugar pero no de la localizacióne exacta, pero no al revés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creamos un data frame\n",
    "tweets = pd.DataFrame()\n",
    "\n",
    "# Extraemos el texto, idioma, y pais de cada tuit, los almacenamos columnas distintas del data frame\n",
    "tweets['text'] = list(map(lambda tweet: tweet['text'], tweets_data))\n",
    "tweets['lang'] = list(map(lambda tweet: tweet['lang'], tweets_data))\n",
    "tweets['country'] = list(map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuales son los cinco idiomas más usados en el dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el agregado de tuits por lenguaje, y lo visualizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "tweets_by_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y los visualizamos\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Idioma', fontsize=15)\n",
    "ax.set_ylabel('Número de tweets' , fontsize=15)\n",
    "ax.set_title('5 idiomas más usados', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuales son los cinco países desde donde se ha tuiteado más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero calculamos el porcentaje de tuits que tienen localización asociada respecto al total, el cual suele ser muy bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "print(\"{:.1%}\".format(sum(tweets_by_country) / len(tweets['country'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el agregado de tuits por pais y los visualizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y los visualizamos\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Idiomas', fontsize=15)\n",
    "ax.set_ylabel('Numero de tutis' , fontsize=15)\n",
    "ax.set_title('5 paises más presentes', fontsize=15, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál de las dos tecnologías ha sido más mencionada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos una columna adicional por cada término que indican si aparece o no ese término en el tuit. A continuación agregamos el número de apariciones en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca un término en un texto\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Añade una columna al dataframe tweets \n",
    "tweets['hadoop'] = tweets['text'].apply(lambda tweet: word_in_text('hadoop', tweet))\n",
    "tweets['spark'] = tweets['text'].apply(lambda tweet: word_in_text('spark', tweet))\n",
    "\n",
    "# Calculamos el número de tweets por cada tecnología big data\n",
    "print('n hadoop:', tweets['hadoop'].value_counts()[True])\n",
    "print('n spark', tweets['spark'].value_counts()[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación entre las distintas tecnologías\n",
    "big_tech = ['hadoop', 'spark']\n",
    "tweets_by_big_tech = [tweets['hadoop'].value_counts()[True], tweets['spark'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(big_tech)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_big_tech, width, alpha=1, color='r')\n",
    "\n",
    "ax.set_ylabel('Número de tuits', fontsize=15)\n",
    "ax.set_title('hadoop vs spark', fontsize=15, fontweight='bold')\n",
    "ax.set_xticks([p + 0.05 * width for p in x_pos])\n",
    "ax.set_xticklabels(big_tech)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cual de las dos tecnologías ha compartido más URL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extramos las urls para hayar el número que hay en el dataset\n",
    "# Extraer url\n",
    "regex = r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+' # URLs\n",
    "url_re = re.compile(regex)\n",
    "    \n",
    "def extract_urls(s):\n",
    "    return url_re.findall(s)\n",
    "    \n",
    "tweets['url'] = tweets['text'].apply(lambda tweet: extract_urls(tweet))\n",
    "\n",
    "print('hadoop:',tweets[tweets['hadoop'] == True]['url'].apply(lambda url: True if url else False).value_counts()[True])\n",
    "print('spark:',tweets[tweets['spark'] == True]['url'].apply(lambda url: True if url else False).value_counts()[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1. Dibujar un gráfico que compare las urls más compartidas de ambas tecnologías\n",
    "- Calcular los 5 usuarios más activos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
